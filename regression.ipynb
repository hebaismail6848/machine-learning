{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center style=\"font-family:Arial\">1. Introduction </center>\n\n<div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">\n    \nIn this notebook, I'll be working with the Ames Housing dataset, a complete dataset containing every aspect of residential homes in Ames, Lowa.\n</div>\n\n<div class=\"alert alert-block alert-info\"\n     style=\"color:black;\n           display:fill;\n           background-color:#ececec;\n           font-size:120%;\n           font-family:Arial\"><center>\n<b>üèÜ My mission is to predict the sales price of the houses based on their characteristics. That way, if we want to look for our dream house in this area, knowing how we want to be, we will see how much it will be.</b></center>\n    </div>\n\n![imageHouses](https://storage.googleapis.com/kaggle-competitions/kaggle/5407/media/housesbanner.png)\n","metadata":{}},{"cell_type":"markdown","source":"## <center style=\"font-family:Arial\">Importing the Data </center>","metadata":{}},{"cell_type":"code","source":"!pip install proplot\nimport warnings\nwarnings.filterwarnings('ignore') ","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-06T00:52:27.262989Z","iopub.execute_input":"2021-10-06T00:52:27.263388Z","iopub.status.idle":"2021-10-06T00:52:37.921396Z","shell.execute_reply.started":"2021-10-06T00:52:27.263297Z","shell.execute_reply":"2021-10-06T00:52:37.920292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ntrain = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:52:37.923662Z","iopub.execute_input":"2021-10-06T00:52:37.924047Z","iopub.status.idle":"2021-10-06T00:52:38.040439Z","shell.execute_reply.started":"2021-10-06T00:52:37.924003Z","shell.execute_reply":"2021-10-06T00:52:38.039479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center style=\"font-family:Arial\">2. EDA </center>","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport proplot as pplt\n\ncorr = train[train.columns].corr()['SalePrice'][:].sort_values(ascending=True).to_frame()\ncorr = corr.drop(corr[corr.SalePrice > 0.99].index)\n\n# Visualization\nfig, ax = plt.subplots(figsize =(9, 9))\nfig.patch.set_facecolor('black')\nax.patch.set_facecolor('black')\n\nax.barh(corr.index, corr.SalePrice, align='center', color = np.where(corr['SalePrice'] < 0, 'crimson', '#89CFF0'))\n\nax.tick_params(axis='both', which='major', labelsize=8)\nax.yaxis.set_label_coords(0, 0)\n\nax.grid(color='white', linewidth=2)\n\n# Remove ticks\nax.xaxis.set_ticks_position('none')\nax.yaxis.set_ticks_position('none')\n\n# Remove axes splines\nfor i in ['top', 'bottom', 'left', 'right']:\n    ax.spines[i].set_visible(False)\n\nax.tick_params(axis='x', colors='white')\nax.tick_params(axis='y', colors='white')\n\n\n# Font\nmpl.rcParams['font.family'] = 'Source Sans Pro'\n\nplt.text(-0.12, 39, \"Correlation\", size=24, color=\"grey\", fontweight=\"bold\");\nplt.text(0.135, 39, \"of\", size=24, color=\"grey\");\nplt.text(0.185, 39, \"SalePrice\", size=24, color=\"#89CFF0\", fontweight=\"bold\");\nplt.text(0.4, 39, \"to\", size=24, color=\"grey\");\nplt.text(0.452, 39, \"Other Features\", size=24, color=\"grey\", fontweight=\"bold\");\n\n# Author\nplt.text(0.9, -7, \"@miguelfzzz\", fontsize=11, ha=\"right\", color='grey');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-06T00:52:38.04159Z","iopub.execute_input":"2021-10-06T00:52:38.04188Z","iopub.status.idle":"2021-10-06T00:52:42.180607Z","shell.execute_reply.started":"2021-10-06T00:52:38.04185Z","shell.execute_reply":"2021-10-06T00:52:42.179599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-size:120%\">In this plot, we can see the correlation of sales price with the rest of the numerical features. These are the highest positive correlations:</div>\n\n* <div style=\"font-size:120%\"><code>OverallQual</code>: Overall material and finish quality</div>\n* <div style=\"font-size:120%\"><code>GrLivArea</code>: Above grade (ground) living area in square feet</div>\n* <div style=\"font-size:120%\"><code>GarageCars</code>: Size of garage by car capacity</div>\n* <div style=\"font-size:120%\"><code>GarageArea</code>: Size of garage in square feet</div>\n* <div style=\"font-size:120%\"><code>TotalBsmtSF</code>: Total square feet of basement area</div>\n* <div style=\"font-size:120%\"><code>1stFlrSF</code>: First Floor square feet</div>","metadata":{}},{"cell_type":"code","source":"# pairplot top 10 correlation features + target\ntop_corr = corr['SalePrice'].sort_values(ascending=False).head(10).index\ntop_corr = top_corr.union(['SalePrice'])\n\nsns.pairplot(train[top_corr]);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-06T00:52:42.183057Z","iopub.execute_input":"2021-10-06T00:52:42.183319Z","iopub.status.idle":"2021-10-06T00:53:29.310917Z","shell.execute_reply.started":"2021-10-06T00:52:42.183289Z","shell.execute_reply":"2021-10-06T00:53:29.309344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center style=\"font-family:Arial\">3. Data Processing and Cleaning </center>","metadata":{}},{"cell_type":"code","source":"print('Training Shape:', train.shape)\nprint('Test Shape:', test.shape)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-06T00:53:29.312534Z","iopub.execute_input":"2021-10-06T00:53:29.312821Z","iopub.status.idle":"2021-10-06T00:53:29.317774Z","shell.execute_reply.started":"2021-10-06T00:53:29.312772Z","shell.execute_reply":"2021-10-06T00:53:29.316937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's save the ID of each dataset\ntrain_id = train['Id']\ntest_id = test['Id']\ndel train['Id']\ndel test['Id']","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.319016Z","iopub.execute_input":"2021-10-06T00:53:29.319284Z","iopub.status.idle":"2021-10-06T00:53:29.333957Z","shell.execute_reply.started":"2021-10-06T00:53:29.319252Z","shell.execute_reply":"2021-10-06T00:53:29.333161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <center style=\"font-family:Arial\">Outliers</center>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">Focusing on the target variable (SalePrice), we can see that there are some outliers in features such as <code>GarageArea</code>, <code>GrLivArea</code> and <code>TotalBsmtSF</code>. </div>","metadata":{}},{"cell_type":"code","source":"train1 = train.copy()\ntrain1 = train1.drop(train1[(train1['GarageArea']>1200) & (train1['SalePrice']<300000)].index)\ntrain1 = train1.drop(train1[(train1['GrLivArea']>4000) & (train1['SalePrice']<300000)].index)\ntrain1 = train1.drop(train1[(train1['TotalBsmtSF']>5000)].index)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.33545Z","iopub.execute_input":"2021-10-06T00:53:29.335949Z","iopub.status.idle":"2021-10-06T00:53:29.36124Z","shell.execute_reply.started":"2021-10-06T00:53:29.335905Z","shell.execute_reply":"2021-10-06T00:53:29.36023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Outliers removed =' , train.shape[0] - train1.shape[0])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-06T00:53:29.363277Z","iopub.execute_input":"2021-10-06T00:53:29.363869Z","iopub.status.idle":"2021-10-06T00:53:29.369718Z","shell.execute_reply.started":"2021-10-06T00:53:29.363819Z","shell.execute_reply":"2021-10-06T00:53:29.368981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <center style=\"font-family:Arial\">Split X and y</center>","metadata":{}},{"cell_type":"code","source":"# Split X and y (in train dataset)\nX = train1.drop('SalePrice', axis=1)\ny = train1['SalePrice'].to_frame()\n\n# Add variable\nX['train'] = 1\ntest['train'] = 0\n\n# Combining train and test for data cleaning \ndf = pd.concat([test, X])","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.3711Z","iopub.execute_input":"2021-10-06T00:53:29.371683Z","iopub.status.idle":"2021-10-06T00:53:29.401098Z","shell.execute_reply.started":"2021-10-06T00:53:29.371641Z","shell.execute_reply":"2021-10-06T00:53:29.400231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Count of Features per Data Type:')\ndf.dtypes.value_counts()  ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-06T00:53:29.404471Z","iopub.execute_input":"2021-10-06T00:53:29.405362Z","iopub.status.idle":"2021-10-06T00:53:29.417887Z","shell.execute_reply.started":"2021-10-06T00:53:29.405314Z","shell.execute_reply":"2021-10-06T00:53:29.416611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Do we have duplicates?\nprint('Number of Duplicates:', len(df[df.duplicated()]))\n\n# Do we have missing values?\nprint('Number of Missing Values:', df.isnull().sum().sum())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-06T00:53:29.41927Z","iopub.execute_input":"2021-10-06T00:53:29.419555Z","iopub.status.idle":"2021-10-06T00:53:29.483495Z","shell.execute_reply.started":"2021-10-06T00:53:29.419522Z","shell.execute_reply":"2021-10-06T00:53:29.482395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center style=\"font-family:Arial\">4. Feature Engineering </center>","metadata":{}},{"cell_type":"markdown","source":"## <center style=\"font-family:Arial\">Missing values</center>","metadata":{}},{"cell_type":"code","source":"print('Missing Values per Column:')\ndf.isnull().sum().sort_values(ascending=False).head(25)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-06T00:53:29.484811Z","iopub.execute_input":"2021-10-06T00:53:29.485047Z","iopub.status.idle":"2021-10-06T00:53:29.509717Z","shell.execute_reply.started":"2021-10-06T00:53:29.485021Z","shell.execute_reply":"2021-10-06T00:53:29.508731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\"><code>PoolQC</code> refers to the pool quality of the house. Data description says that having a NaN in this category means that the house doesn't have a pool.</div>","metadata":{}},{"cell_type":"code","source":"df['PoolQC'] = df['PoolQC'].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.51168Z","iopub.execute_input":"2021-10-06T00:53:29.512047Z","iopub.status.idle":"2021-10-06T00:53:29.518521Z","shell.execute_reply.started":"2021-10-06T00:53:29.512005Z","shell.execute_reply":"2021-10-06T00:53:29.517897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\"><code>MiscFeature</code> refers to miscellaneous features of the house. Data description says that having a NaN in this category means that the house doesn't have any.</div>","metadata":{}},{"cell_type":"code","source":"df['MiscFeature'] = df['MiscFeature'].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.519544Z","iopub.execute_input":"2021-10-06T00:53:29.520301Z","iopub.status.idle":"2021-10-06T00:53:29.53186Z","shell.execute_reply.started":"2021-10-06T00:53:29.520256Z","shell.execute_reply":"2021-10-06T00:53:29.530879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\"><code>Alley</code> refers to the type of alley access to the property. Data description says that having a NaN in this category means that the house doesn't have any.</div>","metadata":{}},{"cell_type":"code","source":"df['Alley'] = df['Alley'].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.533343Z","iopub.execute_input":"2021-10-06T00:53:29.533667Z","iopub.status.idle":"2021-10-06T00:53:29.546051Z","shell.execute_reply.started":"2021-10-06T00:53:29.533625Z","shell.execute_reply":"2021-10-06T00:53:29.545122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\"><code>Fence</code> refers to the type of fencing around the property. Data description says that having a NaN in this category means that the house doesn't have a fence.</div>\n","metadata":{}},{"cell_type":"code","source":"df['Fence'] = df['Fence'].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.547259Z","iopub.execute_input":"2021-10-06T00:53:29.548341Z","iopub.status.idle":"2021-10-06T00:53:29.560421Z","shell.execute_reply.started":"2021-10-06T00:53:29.548293Z","shell.execute_reply":"2021-10-06T00:53:29.559356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\"><code>FireplaceQu</code> refers to the quality of the fireplace. Data description says that having a NaN in this category means that the house doesn't have a fireplace.</div>","metadata":{}},{"cell_type":"code","source":"df['FireplaceQu'] = df['FireplaceQu'].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.562113Z","iopub.execute_input":"2021-10-06T00:53:29.562546Z","iopub.status.idle":"2021-10-06T00:53:29.574983Z","shell.execute_reply.started":"2021-10-06T00:53:29.56248Z","shell.execute_reply":"2021-10-06T00:53:29.573978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\"><code>LotFrontage</code> refers to the distance in feet between the street and the property. Let's impute the missing values with the median of the neighborhood.</div>","metadata":{}},{"cell_type":"code","source":"df['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda i: i.fillna(i.median()))","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.576633Z","iopub.execute_input":"2021-10-06T00:53:29.577Z","iopub.status.idle":"2021-10-06T00:53:29.595276Z","shell.execute_reply.started":"2021-10-06T00:53:29.576959Z","shell.execute_reply":"2021-10-06T00:53:29.59433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">All the features that start with <code>Garage</code> and contain NaN means that those houses don't have a garage.</div>","metadata":{}},{"cell_type":"code","source":"# Let's take a look at the \"Garage\" features\ngarage_cols = [col for col in df if col.startswith('Garage')]\ndf[garage_cols]","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.597073Z","iopub.execute_input":"2021-10-06T00:53:29.597376Z","iopub.status.idle":"2021-10-06T00:53:29.621916Z","shell.execute_reply.started":"2021-10-06T00:53:29.597336Z","shell.execute_reply":"2021-10-06T00:53:29.620926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">We can see that some features are categorical and others numerical. Let's replace the NaN with None in the categorical features and in the numerical features with 0.</div>","metadata":{}},{"cell_type":"code","source":"# For the numerical features:\nfor i in df[garage_cols].select_dtypes(exclude='object').columns:\n    df[i] = df[i].fillna(0)\n\n# For the categorical features:\nfor i in df[garage_cols].select_dtypes(include='object').columns:\n    df[i] = df[i].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.623108Z","iopub.execute_input":"2021-10-06T00:53:29.623336Z","iopub.status.idle":"2021-10-06T00:53:29.639751Z","shell.execute_reply.started":"2021-10-06T00:53:29.62331Z","shell.execute_reply":"2021-10-06T00:53:29.639007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">All the features that start with <code>Bsmt</code> and contain NaN means that those houses don't have a basement.</div>","metadata":{}},{"cell_type":"code","source":"bsmt_cols = [col for col in df if col.startswith('Bsmt')]\n\n# For the numerical features:\nfor i in df[bsmt_cols].select_dtypes(exclude='object').columns:\n    df[i] = df[i].fillna(0)\n\n# For the categorical features:\nfor i in df[bsmt_cols].select_dtypes(include='object').columns:\n    df[i] = df[i].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.640842Z","iopub.execute_input":"2021-10-06T00:53:29.641578Z","iopub.status.idle":"2021-10-06T00:53:29.663772Z","shell.execute_reply.started":"2021-10-06T00:53:29.641534Z","shell.execute_reply":"2021-10-06T00:53:29.662882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">All the features that start with <code>Mas</code> and contain NaN means that those houses don't have a masonry veneer.</div>","metadata":{}},{"cell_type":"code","source":"mas_cols = [col for col in df if col.startswith('Mas')]\n\n# For the numerical features:\nfor i in df[mas_cols].select_dtypes(exclude='object').columns:\n    df[i] = df[i].fillna(0)\n\n# For the categorical features:\nfor i in df[mas_cols].select_dtypes(include='object').columns:\n    df[i] = df[i].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.665133Z","iopub.execute_input":"2021-10-06T00:53:29.665644Z","iopub.status.idle":"2021-10-06T00:53:29.681296Z","shell.execute_reply.started":"2021-10-06T00:53:29.665602Z","shell.execute_reply":"2021-10-06T00:53:29.680468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\"><code>MSZoning</code> refers to the general zoning classification of the sale. Let's impute the missing values with the most common category of the neighborhood.</div>","metadata":{}},{"cell_type":"code","source":"df['MSZoning'] = df.groupby('Neighborhood')['MSZoning'].transform(lambda i: i.fillna(i.value_counts().index[0]))","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.682778Z","iopub.execute_input":"2021-10-06T00:53:29.683485Z","iopub.status.idle":"2021-10-06T00:53:29.711455Z","shell.execute_reply.started":"2021-10-06T00:53:29.683436Z","shell.execute_reply":"2021-10-06T00:53:29.710248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Missing Values left:')\ndf.isnull().sum().sort_values(ascending=False).head(10)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-06T00:53:29.713474Z","iopub.execute_input":"2021-10-06T00:53:29.71376Z","iopub.status.idle":"2021-10-06T00:53:29.738793Z","shell.execute_reply.started":"2021-10-06T00:53:29.713723Z","shell.execute_reply":"2021-10-06T00:53:29.738051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">The rest of the <b>missing values</b> are minimal. I'm going to transform the remaining NaN to the mode of each column.</div>","metadata":{}},{"cell_type":"code","source":"# replace missing values for mode of each column\ndf = df.fillna(df.mode().iloc[0])","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.740086Z","iopub.execute_input":"2021-10-06T00:53:29.740545Z","iopub.status.idle":"2021-10-06T00:53:29.827657Z","shell.execute_reply.started":"2021-10-06T00:53:29.740501Z","shell.execute_reply":"2021-10-06T00:53:29.826929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <center style=\"font-family:Arial\">Transforming some numerical categories into categorical</center>\n\n<div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">Reading the data description shows very clearly that some numerical features represent a specific category.</div>","metadata":{}},{"cell_type":"code","source":"df.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.829174Z","iopub.execute_input":"2021-10-06T00:53:29.829624Z","iopub.status.idle":"2021-10-06T00:53:29.941515Z","shell.execute_reply.started":"2021-10-06T00:53:29.829591Z","shell.execute_reply":"2021-10-06T00:53:29.940872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['MSSubClass'] = df['MSSubClass'].astype(str)\ndf['MoSold'] = df['MoSold'].astype(str)           # months is always categorical\ndf['YrSold'] = df['YrSold'].astype(str)           # year sold just have 5 years","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.943129Z","iopub.execute_input":"2021-10-06T00:53:29.943706Z","iopub.status.idle":"2021-10-06T00:53:29.964916Z","shell.execute_reply.started":"2021-10-06T00:53:29.943661Z","shell.execute_reply":"2021-10-06T00:53:29.964129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <center style=\"font-family:Arial\">Adding relevant features</center>\n\n<div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">Adding relevant features can increase the accuracy of the prediction.</div>","metadata":{}},{"cell_type":"code","source":"df['Total_House_SF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\ndf['Total_Home_Quality'] = (df['OverallQual'] + df['OverallCond'])/2\ndf['Total_Bathrooms'] = (df['FullBath'] + (0.5 * df['HalfBath']) + df['BsmtFullBath'] + (0.5 * df['BsmtHalfBath']))","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.97028Z","iopub.execute_input":"2021-10-06T00:53:29.97084Z","iopub.status.idle":"2021-10-06T00:53:29.98232Z","shell.execute_reply.started":"2021-10-06T00:53:29.970777Z","shell.execute_reply":"2021-10-06T00:53:29.981098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <center style=\"font-family:Arial\">Skewed features</center>\n\n<div style=\"font-size:120%\">Outliers are silent killers in prediction models. In this section, I'll imput the features that are not normally distributed.</div>\n\n* <div style=\"font-size:120%\">First, I'll select the features that have a skew higher than 0.5.</div>","metadata":{}},{"cell_type":"code","source":"numeric_cols = df.select_dtypes(exclude='object').columns\n\nskew_limit = 0.5\nskew_vals = df[numeric_cols].skew()\n\nskew_cols = (skew_vals\n             .sort_values(ascending=False)\n             .to_frame()\n             .rename(columns={0:'Skew'})\n             .query('abs(Skew) > {0}'.format(skew_limit)))\n\nskew_cols","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:29.983751Z","iopub.execute_input":"2021-10-06T00:53:29.984051Z","iopub.status.idle":"2021-10-06T00:53:30.017906Z","shell.execute_reply.started":"2021-10-06T00:53:29.98402Z","shell.execute_reply":"2021-10-06T00:53:30.016828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Font\nmpl.rcParams['font.family'] = 'Source Sans Pro'\nmpl.rcParams['font.size'] = 12\n\nfig, (ax_positive, ax_negative) = plt.subplots(1, 2, figsize=(10, 5))\nfig.patch.set_facecolor('black')\nax_positive.patch.set_facecolor('black')\nax_negative.patch.set_facecolor('black')\n\nsns.histplot(df['BsmtUnfSF'],kde=True, stat='density', linewidth=0, color = '#236AB9', ax=ax_positive)\nsns.histplot(df['YearBuilt'], kde=True, stat='density', linewidth=0,color='#B85B14', ax=ax_negative)\n\nax_positive.tick_params(axis='x', colors='white')\nax_positive.tick_params(axis='y', colors='white')\nax_negative.tick_params(axis='x', colors='white')\nax_negative.tick_params(axis='y', colors='white')\n\nax_positive.set(ylabel='Frequency', xlabel='Value');\nax_negative.set(ylabel='Frequency', xlabel='Value');\n\nax_positive.xaxis.label.set_color('white')\nax_positive.yaxis.label.set_color('white')\nax_negative.xaxis.label.set_color('white')\nax_negative.yaxis.label.set_color('white')\n\nax_positive.set_title('Positive Skew (BsmtUnfSF)', color='white', fontsize= 15)\nax_negative.set_title('Negative Skew (YearBuilt)', color='white', fontsize= 15)\n\n\n\n# Remove axes splines\nfor i in ['top', 'bottom', 'left', 'right']:\n    ax_positive.spines[i].set_visible(False)\n\nfor i in ['top', 'bottom', 'left', 'right']:\n    ax_negative.spines[i].set_visible(False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-06T00:53:30.019258Z","iopub.execute_input":"2021-10-06T00:53:30.019489Z","iopub.status.idle":"2021-10-06T00:53:30.844877Z","shell.execute_reply.started":"2021-10-06T00:53:30.019463Z","shell.execute_reply":"2021-10-06T00:53:30.84395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">In my case, I'll use the Box-Cox transformation to transform all the skew features into a normal distribution.</div>","metadata":{}},{"cell_type":"code","source":"from scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\n# Normalize skewed features\nfor col in skew_cols.index:\n    df[col] = boxcox1p(df[col], boxcox_normmax(df[col] + 1))","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:30.846118Z","iopub.execute_input":"2021-10-06T00:53:30.846379Z","iopub.status.idle":"2021-10-06T00:53:31.15468Z","shell.execute_reply.started":"2021-10-06T00:53:30.846347Z","shell.execute_reply":"2021-10-06T00:53:31.153604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <center style=\"font-family:Arial\">Transforming target</center>","metadata":{}},{"cell_type":"code","source":"import matplotlib.ticker as ticker\n\n# Font\nmpl.rcParams['font.family'] = 'Source Sans Pro'\nmpl.rcParams['font.size'] = 10\n\n# Visualization\nfig, ax = plt.subplots(figsize =(9, 6))\nfig.patch.set_facecolor('black')\nax.patch.set_facecolor('black')\n\nsns.histplot(y['SalePrice'], stat='density', linewidth=0, color = '#ff7f50', kde=True, alpha=0.3);\n\n# Remove ticks\nax.xaxis.set_ticks_position('none')\nax.yaxis.set_ticks_position('none')\n\n# Remove axes splines\nfor i in ['top', 'bottom', 'left', 'right']:\n    ax.spines[i].set_visible(False)\n\n# Remove grid\nplt.grid(b=None)\n\n# Setting thousands with k\nax.xaxis.set_major_formatter(ticker.EngFormatter())\n\nax.tick_params(axis='x', colors='white')\nax.tick_params(axis='y', colors='white')\nax.xaxis.label.set_color('white')\nax.yaxis.label.set_color('white')\n\n# Font\nmpl.rcParams['font.family'] = 'Source Sans Pro'\n\nplt.xlabel('SalePrice', fontsize=11);\n\nplt.text(230000, 0.0000088, \"SalePrice\", size=22, color=\"#ff7f50\", fontweight=\"bold\");\nplt.text(380000, 0.0000088, \"Distribution\", size=22, color=\"grey\", fontweight=\"bold\");","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-06T00:53:31.156434Z","iopub.execute_input":"2021-10-06T00:53:31.156962Z","iopub.status.idle":"2021-10-06T00:53:32.083705Z","shell.execute_reply.started":"2021-10-06T00:53:31.156929Z","shell.execute_reply":"2021-10-06T00:53:32.082477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# log(1+x) transform\ny[\"SalePrice\"] = np.log1p(y[\"SalePrice\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:32.085128Z","iopub.execute_input":"2021-10-06T00:53:32.085465Z","iopub.status.idle":"2021-10-06T00:53:32.091954Z","shell.execute_reply.started":"2021-10-06T00:53:32.085435Z","shell.execute_reply":"2021-10-06T00:53:32.09082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.ticker as ticker\n\n# Font\nmpl.rcParams['font.family'] = 'Source Sans Pro'\nmpl.rcParams['font.size'] = 10\n\n# Visualization\nfig, ax = plt.subplots(figsize =(9, 6))\nfig.patch.set_facecolor('black')\nax.patch.set_facecolor('black')\n\nsns.histplot(y['SalePrice'], stat='density', linewidth=0, color = '#ff7f50', kde=True, alpha=0.3);\n\n# Remove ticks\nax.xaxis.set_ticks_position('none')\nax.yaxis.set_ticks_position('none')\n\n# Remove axes splines\nfor i in ['top', 'bottom', 'left', 'right']:\n    ax.spines[i].set_visible(False)\n\n# Remove grid\nplt.grid(b=None)\n\n# Setting thousands with k\nax.xaxis.set_major_formatter(ticker.EngFormatter())\n\nax.tick_params(axis='x', colors='white')\nax.tick_params(axis='y', colors='white')\nax.xaxis.label.set_color('white')\nax.yaxis.label.set_color('white')\n\n# Font\nmpl.rcParams['font.family'] = 'Source Sans Pro'\n\nplt.xlabel('SalePrice', fontsize=11);\n\nplt.text(11.27, 1.25, \"SalePrice\", size=22, color=\"#ff7f50\", fontweight=\"bold\");\nplt.text(11.92, 1.25, \"Distribution\", size=22, color=\"grey\", fontweight=\"bold\");","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-06T00:53:32.093418Z","iopub.execute_input":"2021-10-06T00:53:32.093744Z","iopub.status.idle":"2021-10-06T00:53:32.78605Z","shell.execute_reply.started":"2021-10-06T00:53:32.093702Z","shell.execute_reply":"2021-10-06T00:53:32.785026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <center style=\"font-family:Arial\">Encoding categorical features</center>","metadata":{}},{"cell_type":"code","source":"categ_cols = df.dtypes[df.dtypes == np.object]        # filtering by categorical variables\ncateg_cols = categ_cols.index.tolist()                # list of categorical fields\n\ndf_enc = pd.get_dummies(df, columns=categ_cols, drop_first=True)   # One hot encoding","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:32.7874Z","iopub.execute_input":"2021-10-06T00:53:32.787629Z","iopub.status.idle":"2021-10-06T00:53:32.849263Z","shell.execute_reply.started":"2021-10-06T00:53:32.787603Z","shell.execute_reply":"2021-10-06T00:53:32.848448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_enc[df_enc['train']==1]\ntest = df_enc[df_enc['train']==0]\nX.drop(['train'], axis=1, inplace=True)\ntest.drop(['train'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T00:53:32.850699Z","iopub.execute_input":"2021-10-06T00:53:32.851266Z","iopub.status.idle":"2021-10-06T00:53:32.868065Z","shell.execute_reply.started":"2021-10-06T00:53:32.85122Z","shell.execute_reply":"2021-10-06T00:53:32.867093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center style=\"font-family:Arial\">5. Modelling </center>","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse(ytrue, ypredicted):\n    return np.sqrt(mean_squared_error(ytrue, ypredicted))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <center style=\"font-family:Arial\">Lasso Regression + Cross-Validation</center>\n    \n* <div style=\"font-size:120%\">Lasso Regression is a linear model that minimizes its cost function.</div>\n\n* <div style=\"font-size:120%\">The cost funtion has a regularization parameter -<b>L1 penalty</b>- with an alpha that tunes the intensity of this penalty term. </div>\n\n* <div style=\"font-size:120%\">This penalty reduces some features to zero, which makes it easier to understand and interpret the prediction.</div>\n\n* <div style=\"font-size:120%\">The larger the value of alpha, the more coefficients are forced to be zero.</div>\n\n* <div style=\"font-size:120%\">The Lasso regression helps reduce over-fitting and feature selection.</div>\n\n","metadata":{}},{"cell_type":"code","source":"lasso = Lasso(max_iter = 100000, normalize = True)\n\nlassocv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\nlassocv.fit(X_train, y_train)\n\nlasso.set_params(alpha=lassocv.alpha_)\nlasso.fit(X_train, y_train)\n\nprint('The Lasso:')\nprint(\"Alpha =\", lassocv.alpha_)\nprint(\"RMSE =\", rmse(y_test, lasso.predict(X_test)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <center style=\"font-family:Arial\">Ridge Regression + Cross-Validation</center>\n\n* <div style=\"font-size:120%\">The Ridge Regression is similar to the Lasso Regression: it's also a linear model that minimizes its cost function and has a regularization parameter -<b>L2 penalty</b>-.</div>\n\n* <div style=\"font-size:120%\">The lower the value of the alpha, the more linear the model will be.</div>\n\n* <div style=\"font-size:120%\">This model doesn't force some features to zero. </div>\n\n* <div style=\"font-size:120%\">The Ridge Regression shrinks the coefficients, and it helps to reduce the model complexity and multi-collinearity.</div>","metadata":{}},{"cell_type":"code","source":"alphas = np.geomspace(1e-9, 5, num=100)\n\nridgecv = RidgeCV(alphas = alphas, scoring = 'neg_mean_squared_error', normalize = True)\nridgecv.fit(X_train, y_train)\n\nridge = Ridge(alpha = ridgecv.alpha_, normalize = True)\nridge.fit(X_train, y_train)\n\nprint('Ridge Regression:')\nprint(\"Alpha =\", ridgecv.alpha_)\nprint(\"RMSE =\", rmse(y_test, ridge.predict(X_test)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <center style=\"font-family:Arial\">Support Vector Regression (SVR) + Cross-Validation</center>","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.svm import SVR\n\n\nkf = KFold(shuffle=True, random_state=1234, n_splits=10)\n\nX_train_scale = RobustScaler().fit_transform(X_train)\nX_test_scale = RobustScaler().fit_transform(X_test)\n\nparameters = {'C':[20, 30, 40], 'gamma': [1e-4, 3e-4, 5e-4],'epsilon':[0.1, 0.01, 0.05]}\nsvr = SVR(kernel='rbf')\nclf = GridSearchCV(svr, parameters, cv=kf)\nclf.fit(X_train_scale,y_train)\nclf.best_params_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svr = SVR(kernel ='rbf', C= 20, epsilon= 0.01, gamma=0.0003)\nsvr.fit(X_train_scale,y_train)\n\nprint('SVR Regression:')\nprint(\"RMSE =\", rmse(y_test, svr.predict(X_test_scale)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size: 24px\">Work in progress... If you liked it so far, please don't forget to comment and upvote. Thank you!</p>","metadata":{}}]}